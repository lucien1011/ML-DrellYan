{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from process_data import simulate_conditional_flow_data_ptscale\n",
    "from Model.ConditionalRealNVP import ConditionalRealNVP\n",
    "from Utils.ObjDict import ObjDict\n",
    "from Utils.mkdir_p import mkdir_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Basic configurables\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "input_csv_path = \"data/train.npy\"\n",
    "saved_model_path = \"/Users/lucien/Downloads/train_condrealnvp_210112_v1/saved_model.h5\"\n",
    "event_size = 1000\n",
    "ndim = 3\n",
    "ncond = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Load models\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "nf_model = ConditionalRealNVP(num_coupling_layers=5,dim=ndim,ncond=ncond)\n",
    "samples = nf_model.distribution.sample(event_size)\n",
    "condition = 1.0 * np.ones((event_size,2))\n",
    "_,_ = nf_model.predict([samples,condition,])\n",
    "nf_model.load_weights(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,_ = nf_model.predict([samples,condition,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load(input_csv_path)\n",
    "condition = (arr[:,-1] - 90.)\n",
    "arr = arr[np.squeeze(np.abs(condition) < 1)]\n",
    "\n",
    "idx_select = np.random.randint(0,arr.shape[0],event_size)\n",
    "arr = arr[idx_select]\n",
    "\n",
    "pt1_mean = np.mean(arr[:,0])\n",
    "pt2_mean = np.mean(arr[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for different conditions\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "#sf_grid = [-0.5,-0.1,0.0,0.1,0.5,]\n",
    "sf_grid = [-0.75,-0.5,-0.1,0.0,0.1,0.5,0.75,]\n",
    "figsize = (50,50)\n",
    "\n",
    "cond_cfgs = [ObjDict(sf1=sf1,sf2=sf2,x=ix,y=iy) for ix,sf1 in enumerate(sf_grid) for iy,sf2 in enumerate(sf_grid)]\n",
    "\n",
    "samples = nf_model.distribution.sample(event_size)\n",
    "fig_pt1,ax_pt1 = plt.subplots(len(sf_grid),len(sf_grid),figsize=figsize)\n",
    "fig_pt2,ax_pt2 = plt.subplots(len(sf_grid),len(sf_grid),figsize=figsize)\n",
    "fig_mll,ax_mll = plt.subplots(len(sf_grid),len(sf_grid),figsize=figsize)\n",
    "\n",
    "for cfg in cond_cfgs:\n",
    "    \n",
    "    condition_str = str(cfg.sf1)+\" \"+str(cfg.sf2)\n",
    "    \n",
    "    x_true,condition = simulate_conditional_flow_data_ptscale(\n",
    "        arr,\n",
    "        pt1_mean=pt1_mean,\n",
    "        pt2_mean=pt2_mean,\n",
    "        batch_size=1,\n",
    "        event_size=event_size,\n",
    "        sf1=cfg.sf1,\n",
    "        sf2=cfg.sf2,\n",
    "    )\n",
    "\n",
    "    x_gen,_ = nf_model.predict([samples,condition,])\n",
    "\n",
    "    ax_pt1[cfg.x,cfg.y].hist(x_true[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True '+condition_str)\n",
    "    ax_pt1[cfg.x,cfg.y].hist(x_gen[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow '+condition_str)\n",
    "    ax_pt1[cfg.x,cfg.y].legend(loc='best')\n",
    "    \n",
    "    ax_pt2[cfg.x,cfg.y].hist(x_true[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True '+condition_str)\n",
    "    ax_pt2[cfg.x,cfg.y].hist(x_gen[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow '+condition_str)\n",
    "    ax_pt2[cfg.x,cfg.y].legend(loc='best')\n",
    "    \n",
    "    ax_mll[cfg.x,cfg.y].hist(x_true[:,2],bins=100,density=1.,histtype='step',range=[0.,20.],label='True '+condition_str)\n",
    "    ax_mll[cfg.x,cfg.y].hist(x_gen[:,2],bins=100,density=1.,histtype='step',range=[0.,20.],label='Flow '+condition_str)\n",
    "    ax_mll[cfg.x,cfg.y].legend(loc='best')\n",
    "    \n",
    "fig_pt1.savefig('pt1.png')\n",
    "fig_pt2.savefig('pt2.png')\n",
    "fig_mll.savefig('mll.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  0\n",
      "Time used: 7.118891000747681s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  1\n",
      "Time used: 6.2698140144348145s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  2\n",
      "Time used: 6.3250932693481445s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  3\n",
      "Time used: 6.399147033691406s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  4\n",
      "Time used: 5.807127952575684s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  5\n",
      "Time used: 5.991120100021362s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  6\n",
      "Time used: 5.716005086898804s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  7\n",
      "Time used: 6.011258840560913s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  8\n",
      "Time used: 6.271391868591309s\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Drawing plot  9\n",
      "Time used: 5.490010023117065s\n"
     ]
    }
   ],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for likelihood\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "from matplotlib import ticker\n",
    "import time\n",
    "\n",
    "ngrid = 10\n",
    "plot_low = -0.6\n",
    "plot_high = 0.6\n",
    "levels = 100 \n",
    "X = np.arange(plot_low, plot_high, (plot_high-plot_low)/ngrid)\n",
    "Y = np.arange(plot_low, plot_high, (plot_high-plot_low)/ngrid)\n",
    "\n",
    "Z = np.zeros((ngrid,ngrid))\n",
    "X_grid, Y_grid = np.meshgrid(X, Y)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    print(\"Drawing plot \",i)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    data_sf1 = 0.5 * (2.*np.random.random_sample()-1.)\n",
    "    data_sf2 = 0.5 * (2.*np.random.random_sample()-1.)\n",
    "    \n",
    "    sf_str = str(data_sf1)+'_'+str(data_sf2)\n",
    "    \n",
    "    x_data,condition = simulate_conditional_flow_data_ptscale(\n",
    "        arr,\n",
    "        pt1_mean=pt1_mean,\n",
    "        pt2_mean=pt2_mean,\n",
    "        batch_size=1,\n",
    "        event_size=event_size,\n",
    "        sf1=data_sf1,\n",
    "        sf2=data_sf2,\n",
    "        )\n",
    "\n",
    "    nf_model.direction = -1\n",
    "    \n",
    "    condition_concat = np.concatenate([\n",
    "        np.concatenate([np.ones((x_data.shape[0],1)) * x,np.ones((x_data.shape[0],1)) * y],axis=1)\n",
    "        for ix,x in enumerate(X) for iy,y in enumerate(Y) \n",
    "        ]\n",
    "    )\n",
    "    x_data_concat = np.concatenate([x_data for ix,x in enumerate(X) for iy,y in enumerate(Y)])\n",
    "    \n",
    "    z_concat = nf_model.batch_log_loss([x_data_concat,condition_concat])\n",
    "    \n",
    "    for ix,x in enumerate(X):\n",
    "        for iy,y in enumerate(Y):\n",
    "            Z[ix,iy] = tf.reduce_mean(z_concat[(ix*ngrid+iy)*x_data.shape[0]:(ix*ngrid+iy+1)*x_data.shape[0]])\n",
    "\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.contourf(X_grid, Y_grid, Z, levels)\n",
    "    fig.colorbar(c)\n",
    "    ax.plot([data_sf2,],[data_sf1,],marker='*',color='red')\n",
    "    ax.set_title(sf_str)\n",
    "    fig.savefig('train_condrealnvp_210111_v4/log_loss_'+sf_str+'.png')\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Time used: \"+str(elapsed_time)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7.6",
   "language": "python",
   "name": "py3.7.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
