{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from process_data import preprocess_conditional_flow_data_cww\n",
    "from Model.ConditionalRealNVP import ConditionalRealNVP,RealNVP\n",
    "from Model.Discriminator import Discriminator\n",
    "from Utils.ObjDict import ObjDict\n",
    "from Utils.mkdir_p import mkdir_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Basic configurables\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "input_csv_path = \"data/train_cww.npy\"\n",
    "saved_sig_model_path = \"output/train_mixnlp_cww_210120_v2/saved_model_sig.h5\"\n",
    "saved_bkg_model_path = \"output/train_mixnlp_cww_210120_v2/saved_model_bkg.h5\"\n",
    "saved_disc_model_path = \"output/train_mixnlp_cww_210120_v2/saved_model_disc.h5\"\n",
    "output_dir = os.path.dirname(saved_sig_model_path)\n",
    "event_size = 4000\n",
    "ndim = 3\n",
    "ncond = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Load models\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "nf_model = ObjDict(\n",
    "    sig = ConditionalRealNVP(num_coupling_layers=5,ndim=ndim,ncond=ncond),\n",
    "    bkg = RealNVP(num_coupling_layers=5,ndim=ndim),\n",
    "    disc = Discriminator([32,32,32,]),\n",
    ")\n",
    "samples = nf_model.sig.distribution.sample(event_size)\n",
    "condition = 1.0 * np.ones((event_size,1))\n",
    "\n",
    "_,_ = nf_model.sig.predict([samples,condition,])\n",
    "nf_model.sig.load_weights(saved_sig_model_path)\n",
    "\n",
    "_,_ = nf_model.bkg.predict(samples)\n",
    "nf_model.bkg.load_weights(saved_bkg_model_path)\n",
    "\n",
    "_ = nf_model.disc.predict(samples)\n",
    "nf_model.disc.load_weights(saved_disc_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load(input_csv_path)\n",
    "sigs,bkg = preprocess_conditional_flow_data_cww(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sigs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-18d6314bbf76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_param\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sigs' is not defined"
     ]
    }
   ],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for different conditions\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "n_dim = 2\n",
    "param_grid = [sigs[idx_param] for idx_param in np.random.randint(0,len(sigs),n_dim*n_dim)]\n",
    "param_grid.sort(key=lambda x: x.condition[0])\n",
    "figsize = (15,15)\n",
    "\n",
    "samples = nf_model.sig.distribution.sample(event_size)\n",
    "fig_m4l,ax_m4l = plt.subplots(n_dim,n_dim,figsize=figsize,constrained_layout=True)\n",
    "fig_mz1,ax_mz1 = plt.subplots(n_dim,n_dim,figsize=figsize,constrained_layout=True)\n",
    "fig_mz2,ax_mz2 = plt.subplots(n_dim,n_dim,figsize=figsize,constrained_layout=True)\n",
    "\n",
    "for i,m in enumerate(param_grid):\n",
    "    \n",
    "    ix = int(i / n_dim)\n",
    "    iy = i % n_dim\n",
    "    \n",
    "    condition_str = str(m.condition[0])\n",
    "    condition = np.ones((event_size,1)) * m.condition[0]\n",
    "\n",
    "    idx_batch = np.random.randint(0,m.x.shape[0],event_size)\n",
    "    \n",
    "    x_sig_true = m.x[idx_batch]\n",
    "    x_sig_gen,_ = nf_model.sig.predict([samples,condition,])\n",
    "    \n",
    "    idx_batch = np.random.randint(0,bkg.x.shape[0],event_size)\n",
    "    x_bkg_true = bkg.x[idx_batch]\n",
    "    condition = np.ones((event_size,1)) * m.condition[0]\n",
    "    x_bkg_gen,_ = nf_model.bkg.predict(samples)\n",
    "\n",
    "    ax_m4l[ix,iy].hist(x_sig_true[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig '+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_sig_gen[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_bkg_true[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg'+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_bkg_gen[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_m4l[ix,iy].legend(loc='best')\n",
    "    ax_m4l[ix,iy].set_title(condition_str)\n",
    "    \n",
    "    ax_mz1[ix,iy].hist(x_sig_true[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_sig_gen[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_bkg_true[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_bkg_gen[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_mz1[ix,iy].legend(loc='best')\n",
    "    ax_mz1[ix,iy].set_title(condition_str)\n",
    "    \n",
    "    ax_mz2[ix,iy].hist(x_sig_true[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig'+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_sig_gen[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_bkg_true[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg '+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_bkg_gen[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_mz2[ix,iy].legend(loc='best')\n",
    "    ax_mz2[ix,iy].set_title(condition_str)\n",
    "    \n",
    "fig_m4l.savefig(os.path.join(output_dir,'m4l.pdf'))\n",
    "fig_mz1.savefig(os.path.join(output_dir,'mZ1.pdf'))\n",
    "fig_mz2.savefig(os.path.join(output_dir,'mZ2.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for likelihood\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "import time\n",
    "\n",
    "n_dim = 1\n",
    "sig_bkg_ratio = 0.2\n",
    "bins = 100\n",
    "figsize = (20,20)\n",
    "\n",
    "bkg_event_size = 5000\n",
    "sig_event_size = int(sig_bkg_ratio * bkg_event_size)\n",
    "\n",
    "nf_model.sig.direction = 1\n",
    "nf_model.sig.direction = 1\n",
    "\n",
    "fig, ax = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "\n",
    "sig_index = np.random.randint(0,len(sigs),1)[0]\n",
    "sig = sigs[sig_index]\n",
    "\n",
    "idx_bkg_batch = np.random.randint(0,bkg.x.shape[0],bkg_event_size)\n",
    "bkg_x = bkg.x[idx_bkg_batch]\n",
    "\n",
    "idx_sig_batch = np.random.randint(0,sig.x.shape[0],sig_event_size)\n",
    "sig_x = sig.x[idx_sig_batch]\n",
    "sig_cond = sig.condition[idx_sig_batch]\n",
    "\n",
    "data = np.concatenate([bkg_x,sig_x],axis=0)\n",
    "\n",
    "plots = [\n",
    "    ObjDict(name=\"mll\",range=[-10.,10.],bins=100,index=0,histtype='step',),\n",
    "    ObjDict(name=\"mZ1\",range=[-10.,10.],bins=100,index=1,histtype='step',),\n",
    "    ObjDict(name=\"mZ2\",range=[-10.,10.],bins=100,index=2,histtype='step',),\n",
    "]\n",
    "\n",
    "for p in plots:\n",
    "    fig, ax = plt.subplots(n_dim,n_dim,figsize=(10,10))\n",
    "    ax.hist(bkg_x[:,p.index],bins=p.bins,label=p.name+' bkg',range=p.range,histtype=p.histtype)\n",
    "    ax.hist(sig_x[:,p.index],bins=p.bins,label=p.name+' sig',range=p.range,histtype=p.histtype)\n",
    "    ax.set_title(str(sig.param))\n",
    "    fig.savefig(os.path.join(output_dir,str(sig_bkg_ratio)+'_'+p.name+'.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucien/.pyenv/versions/3.7.6/lib/python3.7/site-packages/matplotlib/patches.py:1338: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  verts = np.dot(coords, M) + (x + dx, y + dy)\n",
      "/Users/lucien/.pyenv/versions/3.7.6/lib/python3.7/site-packages/matplotlib/patches.py:1338: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  verts = np.dot(coords, M) + (x + dx, y + dy)\n"
     ]
    }
   ],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for posterior\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "n_dim = 1\n",
    "sig_bkg_ratio = 1.0\n",
    "bins = 100\n",
    "figsize = (50,50)\n",
    "\n",
    "bkg_event_size = 200\n",
    "sig_event_size = int(sig_bkg_ratio * bkg_event_size)\n",
    "\n",
    "sig_index = 10\n",
    "\n",
    "nf_model.sig.direction = 1\n",
    "nf_model.bkg.direction = 1\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "\n",
    "sig = sigs[sig_index]\n",
    "\n",
    "idx_bkg_batch = np.random.randint(0,bkg.x.shape[0],bkg_event_size)\n",
    "bkg_x = bkg.x[idx_bkg_batch]\n",
    "\n",
    "idx_sig_batch = np.random.randint(0,sig.x.shape[0],sig_event_size)\n",
    "sig_x = sig.x[idx_sig_batch]\n",
    "sig_cond = sig.condition[idx_sig_batch]\n",
    "\n",
    "data = np.concatenate([bkg_x,sig_x],axis=0)\n",
    "\n",
    "p_sig = np.squeeze(nf_model.disc.predict(data))\n",
    "\n",
    "plot_low = 0.0\n",
    "plot_high = 0.2\n",
    "n_grid = 40\n",
    "x_grid = [plot_low+(plot_high-plot_low)/n_grid*i for i in range(n_grid+1)]\n",
    "\n",
    "condition_concat = np.concatenate([np.ones((data.shape[0],1)) * x for ix,x in enumerate(x_grid)])\n",
    "x_data_concat = np.concatenate([data for ix,x in enumerate(x_grid)])\n",
    "\n",
    "p_sig_concat = np.squeeze(nf_model.disc.predict(x_data_concat))\n",
    "\n",
    "nf_model.sig.direction = -1\n",
    "z_sig_concat = nf_model.sig.batch_log_loss([x_data_concat,condition_concat])\n",
    "z_mix = np.zeros(n_grid+1)\n",
    "z_cond = np.zeros(n_grid+1)\n",
    "norm_mix = 0.\n",
    "norm_cond = 0.\n",
    "\n",
    "nf_model.bkg.direction = -1\n",
    "z_bkg_concat = nf_model.bkg.batch_log_loss(x_data_concat)\n",
    "\n",
    "ln_px = -tf.reduce_sum(z_sig_concat+z_bkg_concat) / n_grid\n",
    "\n",
    "for ig,x in enumerate(x_grid):\n",
    "    idx_start = ig*data.shape[0]\n",
    "    idx_end = (ig+1)*data.shape[0]\n",
    "    z_cond[ig] = tf.reduce_mean(z_sig_concat[idx_start:idx_end])\n",
    "    norm_cond += tf.math.exp(-z_cond[ig]) / n_grid\n",
    "    z_batch = np.multiply(1.-p_sig,z_bkg_concat[idx_start:idx_end]) + np.multiply(p_sig,z_sig_concat[idx_start:idx_end])\n",
    "    z_mix[ig] = tf.reduce_mean(z_batch)\n",
    "    norm_mix += tf.math.exp(-z_mix[ig]) / n_grid\n",
    "\n",
    "y_grid_mix = tf.math.exp(-1.*(z_mix+tf.math.log(norm_mix)))\n",
    "y_grid_cond = tf.math.exp(-1.*(z_cond+tf.math.log(norm_cond)))\n",
    "    \n",
    "y_scale = 'linear'\n",
    "fig, ax = plt.subplots(2,1,figsize=(10,10))\n",
    "\n",
    "ax[0].plot(x_grid,y_grid_mix,label=\"MixtureRealNVP\")\n",
    "ax[0].set_title(str(sig.param))\n",
    "ax[0].set_yscale(y_scale)\n",
    "ax[0].legend(loc='best')\n",
    "plot_y_min = np.amin(y_grid_mix) * 0.5\n",
    "plot_y_max = np.amax(y_grid_mix) * 1.5\n",
    "ax[0].set_ylim(plot_y_min,plot_y_max)\n",
    "ylims = ax[0].get_ylim()\n",
    "ax[0].arrow(sig.condition[0], ylims[1], 0., ylims[0]-ylims[1],)\n",
    "\n",
    "ax[1].plot(x_grid,y_grid_cond,label=\"ConditionalRealNVP\")\n",
    "ax[1].set_title(str(sig.param))\n",
    "ax[1].set_yscale(y_scale)\n",
    "ax[1].legend(loc='best')\n",
    "plot_y_min = np.amin(y_grid_cond) * 0.5\n",
    "plot_y_max = np.amax(y_grid_cond) * 1.5\n",
    "ylims = ax[1].get_ylim()\n",
    "ax[1].set_ylim(plot_y_min,plot_y_max)\n",
    "ylims = ax[0].get_ylim()\n",
    "ax[1].arrow(sig.condition[0], ylims[1], 0., ylims[0]-ylims[1],)\n",
    "\n",
    "param_dir_name = \"cww_\"+str(sig.param)+\"/\"\n",
    "mkdir_p(os.path.join(output_dir,param_dir_name))\n",
    "fig.savefig(os.path.join(output_dir,param_dir_name,str(sig_bkg_ratio)+\"_posterior.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for weighted distributions\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "\n",
    "plots = [\n",
    "    ObjDict(name=\"mll\",range=[-10.,10.],bins=100,index=0,histtype='step',),\n",
    "    ObjDict(name=\"mZ1\",range=[-10.,10.],bins=100,index=1,histtype='step',),\n",
    "    ObjDict(name=\"mZ2\",range=[-10.,10.],bins=100,index=2,histtype='step',),\n",
    "]\n",
    "\n",
    "idx_bkg_batch = np.random.randint(0,bkg.x.shape[0],bkg_event_size)\n",
    "bkg_x = bkg.x[idx_bkg_batch]\n",
    "p_bkg = nf_model.disc.predict(bkg_x)\n",
    "\n",
    "idx_sig_batch = np.random.randint(0,sig.x.shape[0],sig_event_size)\n",
    "sig_x = sig.x[idx_sig_batch]\n",
    "sig_cond = sig.condition[idx_sig_batch]\n",
    "p_sig = nf_model.disc.predict(sig_x)\n",
    "\n",
    "for p in plots:\n",
    "    fig, ax = plt.subplots(n_dim,n_dim,figsize=(10,10))\n",
    "    ax.hist(bkg_x[:,p.index],bins=p.bins,label=p.name+' bkg',range=p.range,histtype=p.histtype)\n",
    "    ax.hist(sig_x[:,p.index],bins=p.bins,label=p.name+' sig',range=p.range,histtype=p.histtype)\n",
    "    ax.set_title(str(sig.param))\n",
    "    ax.legend(loc='best')\n",
    "    fig.savefig(os.path.join(output_dir,param_dir_name,str(sig_bkg_ratio)+'_'+p.name+'.png'))\n",
    "    \n",
    "for p in plots:\n",
    "    fig, ax = plt.subplots(n_dim,n_dim,figsize=(10,10))\n",
    "    ax.hist(bkg_x[:,p.index],bins=p.bins,weights=p_bkg,label=p.name+' bkg',range=p.range,histtype=p.histtype)\n",
    "    ax.hist(sig_x[:,p.index],bins=p.bins,weights=p_sig,label=p.name+' sig',range=p.range,histtype=p.histtype)\n",
    "    ax.set_title(str(sig.param))\n",
    "    ax.legend(loc='best')\n",
    "    fig.savefig(os.path.join(output_dir,param_dir_name,str(sig_bkg_ratio)+'_'+p.name+'_weighted.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7.6",
   "language": "python",
   "name": "py3.7.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
