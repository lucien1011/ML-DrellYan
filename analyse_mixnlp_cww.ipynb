{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from process_data import preprocess_conditional_flow_data_cww\n",
    "from Model.ConditionalRealNVP import ConditionalRealNVP\n",
    "from Model.Discriminator import Discriminator\n",
    "from Utils.ObjDict import ObjDict\n",
    "from Utils.mkdir_p import mkdir_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Basic configurables\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "input_csv_path = \"data/train_cww.npy\"\n",
    "saved_sig_model_path = \"output/train_mixnlp_cww_210120_v1/saved_model_sig_1700.h5\"\n",
    "saved_bkg_model_path = \"output/train_mixnlp_cww_210120_v1/saved_model_bkg_1700.h5\"\n",
    "saved_disc_model_path = \"output/train_mixnlp_cww_210120_v1/saved_model_disc_1700.h5\"\n",
    "output_dir = os.path.dirname(saved_sig_model_path)\n",
    "event_size = 4000\n",
    "ndim = 3\n",
    "ncond = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Load models\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "nf_model = ObjDict(\n",
    "    sig = ConditionalRealNVP(num_coupling_layers=5,dim=ndim,ncond=ncond),\n",
    "    bkg = ConditionalRealNVP(num_coupling_layers=5,dim=ndim,ncond=ncond),\n",
    "    disc = Discriminator([32,32,32,]),\n",
    ")\n",
    "samples = nf_model.sig.distribution.sample(event_size)\n",
    "condition = 1.0 * np.ones((event_size,1))\n",
    "\n",
    "_,_ = nf_model.sig.predict([samples,condition,])\n",
    "nf_model.sig.load_weights(saved_sig_model_path)\n",
    "\n",
    "_,_ = nf_model.bkg.predict([samples,condition,])\n",
    "nf_model.bkg.load_weights(saved_bkg_model_path)\n",
    "\n",
    "_ = nf_model.disc.predict(samples)\n",
    "nf_model.disc.load_weights(saved_disc_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.load(input_csv_path)\n",
    "sigs,bkg = preprocess_conditional_flow_data_cww(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for different conditions\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "n_dim = 5\n",
    "param_grid = [sigs[idx_param] for idx_param in np.random.randint(0,len(sigs),n_dim*n_dim)]\n",
    "param_grid.sort(key=lambda x: x.condition[0])\n",
    "figsize = (50,50)\n",
    "\n",
    "samples = nf_model.sig.distribution.sample(event_size)\n",
    "fig_m4l,ax_m4l = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "fig_mz1,ax_mz1 = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "fig_mz2,ax_mz2 = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "\n",
    "for i,m in enumerate(param_grid):\n",
    "    \n",
    "    ix = int(i / n_dim)\n",
    "    iy = i % n_dim\n",
    "    \n",
    "    condition_str = str(m.condition[0])\n",
    "    condition = np.ones((event_size,1)) * m.condition[0]\n",
    "\n",
    "    idx_batch = np.random.randint(0,m.x.shape[0],event_size)\n",
    "    \n",
    "    x_sig_true = m.x[idx_batch]\n",
    "    x_sig_gen,_ = nf_model.sig.predict([samples,condition,])\n",
    "    \n",
    "    idx_batch = np.random.randint(0,bkg.x.shape[0],event_size)\n",
    "    x_bkg_true = bkg.x[idx_batch]\n",
    "    condition = np.ones((event_size,1)) * m.condition[0]\n",
    "    x_bkg_gen,_ = nf_model.bkg.predict([samples,condition,])\n",
    "\n",
    "    ax_m4l[ix,iy].hist(x_sig_true[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig '+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_sig_gen[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_bkg_true[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg'+condition_str)\n",
    "    ax_m4l[ix,iy].hist(x_bkg_gen[:,0],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_m4l[ix,iy].legend(loc='best')\n",
    "    ax_m4l[ix,iy].set_title(condition_str)\n",
    "    \n",
    "    ax_mz1[ix,iy].hist(x_sig_true[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_sig_gen[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_bkg_true[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg '+condition_str)\n",
    "    ax_mz1[ix,iy].hist(x_bkg_gen[:,1],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_mz1[ix,iy].legend(loc='best')\n",
    "    ax_mz1[ix,iy].set_title(condition_str)\n",
    "    \n",
    "    ax_mz2[ix,iy].hist(x_sig_true[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True sig'+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_sig_gen[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow sig '+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_bkg_true[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='True bkg '+condition_str)\n",
    "    ax_mz2[ix,iy].hist(x_bkg_gen[:,2],bins=100,density=1.,histtype='step',range=[-10.,10.],label='Flow bkg '+condition_str)\n",
    "    ax_mz2[ix,iy].legend(loc='best')\n",
    "    ax_mz2[ix,iy].set_title(condition_str)\n",
    "    \n",
    "fig_m4l.savefig(os.path.join(output_dir,'m4l.png'))\n",
    "fig_mz1.savefig(os.path.join(output_dir,'mZ1.png'))\n",
    "fig_mz2.savefig(os.path.join(output_dir,'mZ2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________________________________ ||\n",
    "# Make plots for likelihood\n",
    "# __________________________________________________________________ ||\n",
    "\n",
    "import time\n",
    "\n",
    "n_dim = 3\n",
    "sig_bkg_ratio = 0.1\n",
    "param_grid = [sigs[idx_param] for idx_param in np.random.randint(0,len(sigs),n_dim*n_dim)]\n",
    "param_grid.sort(key=lambda x: x.condition[0])\n",
    "\n",
    "plot_low = 0.0\n",
    "plot_high = 0.2\n",
    "n_grid = 10\n",
    "x_grid = [plot_low+(plot_high-plot_low)/n_grid*i for i in range(n_grid+1)]\n",
    "\n",
    "bkg_event_size = 5000\n",
    "sig_event_size = int(sig_bkg_ratio * bkg_event_size)\n",
    "\n",
    "z = np.zeros(n_grid+1)\n",
    "fig, ax = plt.subplots(n_dim,n_dim,figsize=figsize)\n",
    "\n",
    "for i,p in enumerate(param_grid):\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    print(\"Drawing plot \",i,\" with param \",p.condition[0], \"signal background ratio \",sig_bkg_ratio)\n",
    "    \n",
    "    ix = int(i / n_dim)\n",
    "    iy = i % n_dim\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    condition_str = str(p)\n",
    "\n",
    "    nf_model.sig.direction = -1\n",
    "    nf_model.bkg.direction = -1\n",
    "    \n",
    "    idx_sig_batch = np.random.randint(0,p.x.shape[0],sig_event_size)\n",
    "    idx_bkg_batch = np.random.randint(0,bkg.shape[0],bkg_event_size)\n",
    "    \n",
    "    condition_concat = np.concatenate([np.ones((event_size,1)) * x for ix,x in enumerate(x_grid)])\n",
    "    x_data_concat = np.concatenate([p.x[idx_batch] for ix,x in enumerate(x_grid)])\n",
    "    \n",
    "    z_concat = nf_model.batch_log_loss([x_data_concat,condition_concat])\n",
    "    \n",
    "    for ig,x in enumerate(x_grid):\n",
    "        z[ig] = tf.reduce_mean(z_concat[ig*idx_batch.shape[0]:(ig+1)*idx_batch.shape[0]])\n",
    "\n",
    "    ax[ix,iy].plot(x_grid,z,)\n",
    "    ylims = ax[ix,iy].get_ylim()\n",
    "    ax[ix,iy].arrow(p.condition[0], ylims[1], 0., ylims[0]-ylims[1],)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Time used: \"+str(elapsed_time)+\"s\")\n",
    "    \n",
    "fig.savefig(os.path.join(output_dir,'log_loss.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.7.6",
   "language": "python",
   "name": "py3.7.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
